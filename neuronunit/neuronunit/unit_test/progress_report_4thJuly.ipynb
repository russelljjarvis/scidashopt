{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bokeh in /usr/local/lib/python2.7/dist-packages (0.12.16)\n",
      "Requirement already satisfied: tornado>=4.3 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (4.4.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python2.7/dist-packages (from bokeh) (17.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python2.7/dist-packages/Jinja2-2.8-py2.7.egg (from bokeh) (2.8)\n",
      "Requirement already satisfied: futures>=3.0.3 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (3.0.5)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python2.7/dist-packages (from bokeh) (3.12)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (2.6.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (1.14.0)\n",
      "Requirement already satisfied: backports-abc>=0.4 in /home/russell/.local/lib/python2.7/site-packages (from tornado>=4.3->bokeh) (0.5)\n",
      "Requirement already satisfied: certifi in /home/russell/.local/lib/python2.7/site-packages (from tornado>=4.3->bokeh) (2018.1.18)\n",
      "Requirement already satisfied: singledispatch in /home/russell/.local/lib/python2.7/site-packages (from tornado>=4.3->bokeh) (3.4.0.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python2.7/dist-packages (from packaging>=16.8->bokeh) (2.1.10)\n",
      "Requirement already satisfied: MarkupSafe in /usr/local/lib/python2.7/dist-packages/MarkupSafe-0.23-py2.7-linux-x86_64.egg (from Jinja2>=2.7->bokeh) (0.23)\n",
      "\u001b[31mpyneuroml 0.3.11 requires airspeed==0.5.4dev-20150515, which is not installed.\u001b[0m\n",
      "\u001b[31mpyneuroml 0.3.11 requires libNeuroML>=0.2.39, which is not installed.\u001b[0m\n",
      "\u001b[31mpyneuroml 0.3.11 requires lxml, which is not installed.\u001b[0m\n",
      "\u001b[31mpyneuroml 0.3.11 requires pylems>=0.4.9.1, which is not installed.\u001b[0m\n",
      "\u001b[31msciunit 0.19 requires bs4, which is not installed.\u001b[0m\n",
      "\u001b[31msciunit 0.19 requires cypy>=0.2, which is not installed.\u001b[0m\n",
      "\u001b[31msciunit 0.19 requires gitpython, which is not installed.\u001b[0m\n",
      "\u001b[31msciunit 0.19 requires lxml, which is not installed.\u001b[0m\n",
      "\u001b[31mowtests 0.1 requires neuronunit>=0.19, which is not installed.\u001b[0m\n",
      "\u001b[31mexecnet 1.5.0 requires apipkg>=1.4, which is not installed.\u001b[0m\n",
      "\u001b[31mbackports-tempfile 1.0 requires backports.weakref, which is not installed.\u001b[0m\n",
      "\u001b[31mneo 0.4.1 has requirement quantities>=0.9.0, but you'll have quantities 0+unknown which is incompatible.\u001b[0m\n",
      "\u001b[31msciunit 0.19 has requirement quantities==0.12.1, but you'll have quantities 0+unknown which is incompatible.\u001b[0m\n",
      "Requirement already satisfied: bokeh in /usr/local/lib/python2.7/dist-packages (0.12.16)\n",
      "Requirement already satisfied: tornado>=4.3 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (4.4.2)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python2.7/dist-packages (from bokeh) (17.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python2.7/dist-packages/Jinja2-2.8-py2.7.egg (from bokeh) (2.8)\n",
      "Requirement already satisfied: futures>=3.0.3 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (3.0.5)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python2.7/dist-packages (from bokeh) (3.12)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (2.6.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /home/russell/.local/lib/python2.7/site-packages (from bokeh) (1.14.0)\n",
      "Requirement already satisfied: backports-abc>=0.4 in /home/russell/.local/lib/python2.7/site-packages (from tornado>=4.3->bokeh) (0.5)\n",
      "Requirement already satisfied: certifi in /home/russell/.local/lib/python2.7/site-packages (from tornado>=4.3->bokeh) (2018.1.18)\n",
      "Requirement already satisfied: singledispatch in /home/russell/.local/lib/python2.7/site-packages (from tornado>=4.3->bokeh) (3.4.0.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python2.7/dist-packages (from packaging>=16.8->bokeh) (2.1.10)\n",
      "Requirement already satisfied: MarkupSafe in /usr/local/lib/python2.7/dist-packages/MarkupSafe-0.23-py2.7-linux-x86_64.egg (from Jinja2>=2.7->bokeh) (0.23)\n",
      "\u001b[31mpyneuroml 0.3.11 requires airspeed==0.5.4dev-20150515, which is not installed.\u001b[0m\n",
      "\u001b[31mpyneuroml 0.3.11 requires libNeuroML>=0.2.39, which is not installed.\u001b[0m\n",
      "\u001b[31mpyneuroml 0.3.11 requires lxml, which is not installed.\u001b[0m\n",
      "\u001b[31mpyneuroml 0.3.11 requires pylems>=0.4.9.1, which is not installed.\u001b[0m\n",
      "\u001b[31msciunit 0.19 requires bs4, which is not installed.\u001b[0m\n",
      "\u001b[31msciunit 0.19 requires cypy>=0.2, which is not installed.\u001b[0m\n",
      "\u001b[31msciunit 0.19 requires gitpython, which is not installed.\u001b[0m\n",
      "\u001b[31msciunit 0.19 requires lxml, which is not installed.\u001b[0m\n",
      "\u001b[31mowtests 0.1 requires neuronunit>=0.19, which is not installed.\u001b[0m\n",
      "\u001b[31mexecnet 1.5.0 requires apipkg>=1.4, which is not installed.\u001b[0m\n",
      "\u001b[31mbackports-tempfile 1.0 requires backports.weakref, which is not installed.\u001b[0m\n",
      "\u001b[31mneo 0.4.1 has requirement quantities>=0.9.0, but you'll have quantities 0+unknown which is incompatible.\u001b[0m\n",
      "\u001b[31msciunit 0.19 has requirement quantities==0.12.1, but you'll have quantities 0+unknown which is incompatible.\u001b[0m\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'bokeh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e77014626954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'bokeh'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e77014626954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install bokeh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnDataSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHoverTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'bokeh'"
     ]
    }
   ],
   "source": [
    "!pip install bokeh\n",
    "\n",
    "try:\n",
    "    import bokeh\n",
    "except:\n",
    "    !pip install bokeh\n",
    "    import bokeh\n",
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "%matplotlib inline\n",
    "from bokeh.plotting import show, output_notebook\n",
    "from bokeh.models import ColumnDataSource, OpenURL, TapTool\n",
    "import os\n",
    "output_notebook()\n",
    "os.system('jupyter trust Visualisation_search_terms_reading_levelGS.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rick Gerkin [3:16 PM]\n",
    "Here is the list of ideas/suggestions I promised:\n",
    "- Reduce the amount of stuff in the progress report.  You can have a different one for each week, or just copy them as needed, and remove all the stuff that isn't pertinent to the current work.  You can always bring it back in later.  If rendering figures, just render the ones you need to show the point.  \n",
    "\n",
    "\n",
    "- Show some raw values in the table, e.g. the input resistance for a candidate model.  You don't need to show the test observation values, except maybe outside the table on a separate line (since they are the same for every gene using the same test).  \n",
    "\n",
    "- Try scaling up to three parameters - you can reduce the grid sampling to, say 6x6x6 (from 10x10 for 2 parameters), that way it isn't too much more computationally complex. \n",
    "\n",
    "- Then you can show the corresponding figures and tables for this three parameter case, show all of the 2D cross-sections through the global optimum.  Or maybe you can think of other ways for showing 3D.  \n",
    "- Make sure the code isn't getting too unwieldy.  Condense and refactor and clean up regularly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "!pip install prettyplotlib\n",
    "import prettyplotlib as ppl\n",
    "from prettyplotlib import plt\n",
    "from prettyplotlib import brewer2mpl\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "green_purple = brewer2mpl.get_map('PRGn', 'diverging', 11).mpl_colormap\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from pylab import rcParams\n",
    "from neuronunit.optimization.results_analysis import make_report, min_max\n",
    "with open('pre_grid_reports.p','rb') as f:#\n",
    "    grid_results = pickle.load(f)\n",
    "\n",
    "with open('pre_ga_reports.p','rb') as f:\n",
    "    package = pickle.load(f)\n",
    "pop = package[0]\n",
    "print(pop[0].dtc.attrs.items())\n",
    "history = package[4]\n",
    "gen_vs_pop =  package[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "import scipy.ndimage as ndi\n",
    "import neuronunit.optimization.exhaustive_search as es\n",
    "\n",
    "data = np.zeros((6, 6, 6))\n",
    "#data = ndi.filters.gaussian_filter(data, sigma=1)\n",
    "\n",
    "axis = [ [ str('vr'), str('a'), str('b') ], [ str('vr'), str('b'), str('a')], [ str('b'), str('a'), str('vr') ] ]\n",
    "\n",
    "gen_vs_pop = package[6]    \n",
    "pop = gen_vs_pop[-1]\n",
    "\n",
    "k = axis[0]\n",
    "ee = [ np.sum(list(i.dtc.scores.values())) for i in grid_results ]\n",
    "zz = [ i.dtc.attrs[k[2]] for i in grid_results ]\n",
    "yy = [ i.dtc.attrs[k[1]] for i in grid_results ]\n",
    "xx = [ i.dtc.attrs[k[0]] for i in grid_results ]\n",
    "print(xx,yy,zz)\n",
    "hvc = es.make_hyper_cube(xx,yy,zz,ee)\n",
    "\n",
    "\n",
    "def cube_show_slider(cube, axis=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Display a 3d ndarray with a slider to move along the third dimension.\n",
    "    Extra keyword arguments are passed to imshow\n",
    "    \"\"\"\n",
    "    # check dim\n",
    "    if not cube.ndim == 3:\n",
    "        raise ValueError(\"cube should be an ndarray with ndim == 3\")\n",
    "\n",
    "    # generate figure\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    fig.subplots_adjust(left=0.25, bottom=0.25)\n",
    "\n",
    "    # select first image\n",
    "    s = [slice(0, 1) if i == axis else slice(None) for i in range(3)]\n",
    "    #print(s)\n",
    "    im = cube[s].squeeze()\n",
    "    #print(im)\n",
    "    # display image\n",
    "    l = ax.matshow(im, **kwargs)\n",
    "    cb = plt.colorbar(l)\n",
    "    cb.set_clim(vmin=data.min(), vmax=data.max())\n",
    "    cb.draw_all()\n",
    "\n",
    "    # define slider\n",
    "    axcolor = 'lightgoldenrodyellow'\n",
    "    ax = fig.add_axes([0.25, 0.1, 0.65, 0.03])#, axisbg=axcolor)\n",
    "    slideryo = Slider(ax, 'Axis %i index' % axis, 0, cube.shape[axis] - 1, valinit=0, valfmt='%i')\n",
    "\n",
    "    def update(val):\n",
    "        ind = int(slideryo.val)\n",
    "        s = [slice(ind, ind + 1) if i == axis else slice(None) for i in range(3)]\n",
    "        im = cube[s].squeeze()\n",
    "        l.set_data(im, **kwargs)\n",
    "        cb.set_clim(vmin=data.min(), vmax=data.max())\n",
    "        cb.formatter.set_powerlimits((0, 0))\n",
    "        cb.update_ticks()\n",
    "        cb.draw_all()\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    slideryo.on_changed(update)\n",
    "    plt.show()\n",
    "\n",
    "#print(np.shape(hvc))\n",
    "#print(k[2],k[1],k[0])\n",
    "\n",
    "#cube_show_slider(hvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from neuronunit imp\n",
    "\n",
    "from neuronunit.models.reduced import ReducedModel\n",
    "from neuronunit.optimization.model_parameters import model_params, path_params\n",
    "import quantities as pq\n",
    "\n",
    "super_pop = []\n",
    "\n",
    "for gp in gen_vs_pop:\n",
    "    super_pop.extend(gp)\n",
    "minga,maxga = min_max(super_pop)\n",
    "mingr,maxgr = min_max(grid_results)\n",
    "abs_min = np.min((mingr[1],minga[1]))\n",
    "abs_max = np.max((maxgr[1],maxga[1]))\n",
    "v = list(np.linspace(abs_min, abs_max, 15, endpoint=True))\n",
    "#print(dir(maxgr[2].vtest))\n",
    "#print(dir(maxgr[2]))#.attrs)\n",
    "\n",
    "def plot(dtc):\n",
    "    model = ReducedModel(path_params['model_path'],name=str('vanilla'),backend='NEURON')\n",
    "    xargs = {}\n",
    "\n",
    "    xargs['injected_square_current'] = {}\n",
    "    xargs['injected_square_current']['duration'] = 1000 * pq.ms\n",
    "    xargs['injected_square_current']['amplitude'] = dtc[2].rheobase['value']\n",
    "    xargs['injected_square_current']['delay'] = 250 * pq.ms # + 150\n",
    "    model.set_attrs(dtc[2].attrs)\n",
    "    model.inject_square_current(xargs)\n",
    "\n",
    "    \n",
    "\n",
    "    v_m = model.get_membrane_potential()\n",
    "    from neuronunit import capabilities as cap\n",
    "    threshold = cap.spikes2thresholds(v_m)\n",
    "    ts = model.results['t'] # time signal\n",
    "    plt.clf()\n",
    "    plt.plot(ts,v_m)\n",
    "    plt.show()\n",
    "    \n",
    "_ = plot(mingr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz = [ list(i.dtc.scores.items()) for i in grid_results ]\n",
    "#print(zz)\n",
    "xx = [ list(i.dtc.scores.items()) for i in pop ]\n",
    "#print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "super_set = []\n",
    "length = len(gen_vs_pop)\n",
    "for i, pop in enumerate(gen_vs_pop):        \n",
    "    other_points = []\n",
    "    pf_points = []\n",
    "    hof_points = []    \n",
    "    labels = []\n",
    "    for p in pop:\n",
    "        xyz = []\n",
    "        for k,v in p.dtc.attrs.items():\n",
    "            xyz.append(v)\n",
    "            labels.append(k)\n",
    "        other_points.append(xyz)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    errors = [ np.sum(list(p.dtc.scores.values())) for p in pop ]\n",
    "    xx = [ i[0] for i in other_points ]\n",
    "    yy = [ i[1] for i in other_points ]\n",
    "    zz = [ i[2] for i in other_points ]\n",
    "    if len(super_set) !=0 :\n",
    "        for ss in super_set:\n",
    "            ops, ers = ss\n",
    "            p = ax.scatter([i[0] for i in ops], [ i[1] for i in ops], [i[2] for i in ops], alpha=0.0525, c=ers, cmap='jet', marker='o', vmin=abs_min, vmax=abs_max)\n",
    "   \n",
    "    p = ax.scatter(xx, yy, zz, c=errors, cmap='jet', marker='o', vmin=abs_min, vmax=abs_max)\n",
    "    cb = fig.colorbar(p)\n",
    "    cb.set_label('summed scores')\n",
    "        \n",
    "    zz = [ np.sum(list(i.dtc.scores.values())) for i in grid_results ]\n",
    "    zz_sorted = sorted([( np.sum(list(i.dtc.scores.values())), index) for index,i in enumerate(grid_results) ])\n",
    "    gbest = zz_sorted[0]\n",
    "    gworst = zz_sorted[-1]\n",
    "    assert gbest!=gworst\n",
    "    print(gbest,gworst)\n",
    "    gworst_grid_attrs = grid_results[gworst[1]].dtc.attrs\n",
    "    gbest_grid_attrs = grid_results[gbest[1]].dtc.attrs\n",
    "    \n",
    "    '''\n",
    "    xyz = []\n",
    "    for k,v in pop[0].dtc.attrs.items():\n",
    "        xyz.append(gworst_grid_attrs[k])\n",
    "    p = ax.scatter(xyz[0], xyz[1], xyz[2],cmap='jet', marker='*',label='worst', vmin=abs_min, vmax=abs_max)\n",
    "    xyz = []\n",
    "    for k,v in pop[0].dtc.attrs.items():\n",
    "        xyz.append(gbest_grid_attrs[k])    \n",
    "    p = ax.scatter(xyz[0], xyz[1], xyz[2],cmap='jet', marker='^',label='best', vmin=abs_min, vmax=abs_max)\n",
    "    '''\n",
    "\n",
    "    ax.set_xlabel(str(labels[0]))\n",
    "    ax.set_ylabel(str(labels[1]))\n",
    "    ax.set_zlabel(str(labels[2]))\n",
    "    plt.savefig('particle_cube_'+str(float(i/length))+str('.png'))\n",
    "    super_set.append((other_points,errors))    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "with open('pre_grid_reports.p','rb') as f:\n",
    "    grid_results = pickle.load(f)\n",
    "    \n",
    "\n",
    "with open('pre_ga_reports.p','rb') as f:\n",
    "    package = pickle.load(f)\n",
    "\n",
    "from neuronunit.optimization import exhaustive_search\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "axis = [ [ str('vr'), str('a'), str('b') ], [ str('vr'), str('b'), str('a')], [ str('b'), str('a'), str('vr') ] ]\n",
    "\n",
    "gen_vs_pop = package[6]    \n",
    "pop = gen_vs_pop[-1]\n",
    "\n",
    "for k in axis:    \n",
    "    \n",
    "    zz = [ np.sum(list(i.dtc.scores.values())) for i in grid_results ]\n",
    "    yy = [ i.dtc.attrs[k[1]] for i in grid_results ]\n",
    "    xx = [ i.dtc.attrs[k[0]] for i in grid_results ]\n",
    "\n",
    "    last_frame = len(gen_vs_pop)\n",
    "    other_points = []\n",
    "    pf_points = []\n",
    "    hof_points = []\n",
    "    labels = []\n",
    "    \n",
    "    pf = package[2]\n",
    "    hof = package[1]\n",
    "    \n",
    "    for p in pop:\n",
    "        xy = []\n",
    "        for key in k:\n",
    "            v = p.dtc.attrs[key]\n",
    "            xy.append(v)\n",
    "            labels.append(key)\n",
    "            other_points.append(xy)\n",
    "            \n",
    "            \n",
    "    for p in pf:\n",
    "        xy = []\n",
    "        for key in k:\n",
    "            v = p.dtc.attrs[key]\n",
    "            xy.append(v)\n",
    "            labels.append(key)\n",
    "            pf_points.append(xy)            \n",
    "       \n",
    "    for p in hof:\n",
    "        xy = []\n",
    "        for key in k:\n",
    "            v = p.dtc.attrs[key]\n",
    "            xy.append(v)\n",
    "            labels.append(key)\n",
    "            hof_points.append(xy)        \n",
    "\n",
    "            \n",
    "    zi, yi, xi = np.histogram2d(yy, xx, bins=(6,6), weights=zz, normed=False)\n",
    "    counts, _, _ = np.histogram2d(yy, xx, bins=(6,6))\n",
    "    #binned , _, _ = np.histogram(zce, bins=10)\n",
    "\n",
    "    zi = zi / counts\n",
    "    zi = np.ma.masked_invalid(zi)\n",
    "    fig, ax = plt.subplots()\n",
    "    #scat = ppl.pcolormesh(fig, ax, xi, yi, zi, edgecolors='black', cmap=green_purple)\n",
    "    scat = ax.pcolormesh(xi, yi, zi, edgecolors='black', cmap=green_purple)\n",
    "    \n",
    "\n",
    "\n",
    "    fig.colorbar(scat)\n",
    "    ax.margins(0.05)\n",
    "\n",
    "    #if i == last_frame-1:\n",
    "    for xy in hof_points:\n",
    "        ax.plot(xy[0], xy[1],'y*',label ='hall of fame') \n",
    "    for xy in pf_points:\n",
    "        ax.plot(xy[0], xy[1],'b*',label ='pareto front') \n",
    "        #legend = ax.legend([rect(\"r\"), rect(\"g\"), rect(\"b\")], [\"gene population\",\"pareto front\",\"hall of fame\"])\n",
    "\n",
    "\n",
    "    for xy in other_points:\n",
    "        ax.plot(xy[0], xy[1],'ro',label ='gene population') \n",
    "    ax.margins(0.05)\n",
    "\n",
    "    plt.xlabel(labels[0])\n",
    "    plt.ylabel(labels[1])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "gen_vs_pop = package[6]    \n",
    "pop = gen_vs_pop[-1]\n",
    "for k in axis:    \n",
    "    zz = [ np.sum(list(i.dtc.scores.values())) for i in grid_results ]\n",
    "    zz_sorted = sorted([( np.sum(list(i.dtc.scores.values())), index) for index,i in enumerate(grid_results) ])\n",
    "    gbest = zz_sorted[0]\n",
    "    gworst = zz_sorted[-1]\n",
    "    assert gbest!=gworst\n",
    "    gworst_grid_attrs = grid_results[gworst[1]].dtc.attrs\n",
    "    gbest_grid_attrs = grid_results[gbest[1]].dtc.attrs\n",
    "    gba = gbest_grid_attrs[k[2]]   \n",
    "    zz = [ np.sum(list(i.dtc.attrs.values())) for i in grid_results ]\n",
    "    zce = [ np.sum(list(i.dtc.scores.values())) for i in grid_results if i.dtc.attrs[k[2]] == gba]\n",
    "    yy = [ i.dtc.attrs[k[1]] for i in grid_results if i.dtc.attrs[k[2]] == gba ]\n",
    "    xx = [ i.dtc.attrs[k[0]] for i in grid_results if i.dtc.attrs[k[2]] == gba ]\n",
    "    last_frame = len(gen_vs_pop)\n",
    "    other_points = []\n",
    "    pf_points = []\n",
    "    hof_points = []\n",
    "    labels = []\n",
    "    \n",
    "    pf = package[2]\n",
    "    hof = package[1]\n",
    "    \n",
    "    for p in pop:\n",
    "        xy = []\n",
    "        for key in k:\n",
    "            v = p.dtc.attrs[key]\n",
    "            xy.append(v)\n",
    "            labels.append(key)\n",
    "            other_points.append(xy)\n",
    "            \n",
    "            \n",
    "    for p in pf:\n",
    "        xy = []\n",
    "        for key in k:\n",
    "            v = p.dtc.attrs[key]\n",
    "            xy.append(v)\n",
    "            labels.append(key)\n",
    "            pf_points.append(xy)            \n",
    "       \n",
    "    for p in hof:\n",
    "        xy = []\n",
    "        for key in k:\n",
    "            v = p.dtc.attrs[key]\n",
    "            xy.append(v)\n",
    "            labels.append(key)\n",
    "            hof_points.append(xy)        \n",
    "\n",
    "            \n",
    "    zi, yi, xi = np.histogram2d(yy, xx, bins=(6,6), weights=zce, normed=False)\n",
    "    counts, _, _ = np.histogram2d(yy, xx, bins=(6,6))\n",
    "\n",
    "    zi = zi / counts\n",
    "    zi = np.ma.masked_invalid(zi)\n",
    "    fig, ax = plt.subplots()\n",
    "    scat = ax.pcolormesh(xi, yi, zi, edgecolors='black', cmap=green_purple)\n",
    "\n",
    "    fig.colorbar(scat)\n",
    "    ax.margins(0.05)\n",
    "\n",
    "    #if i == last_frame-1:\n",
    "    for xy in hof_points:\n",
    "        ax.plot(xy[0], xy[1],'y*',label ='hall of fame') \n",
    "    for xy in pf_points:\n",
    "        ax.plot(xy[0], xy[1],'b*',label ='pareto front') \n",
    "        #legend = ax.legend([rect(\"r\"), rect(\"g\"), rect(\"b\")], [\"gene population\",\"pareto front\",\"hall of fame\"])\n",
    "\n",
    "\n",
    "    for xy in other_points:\n",
    "        ax.plot(xy[0], xy[1],'ro',label ='gene population') \n",
    "    ax.margins(0.05)\n",
    "\n",
    "    plt.xlabel(labels[0])\n",
    "    plt.ylabel(labels[1])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So imagine 6 2D plots.  The first three are:  XY at Z=z, XZ at Y=y, and YZ at X=x, where x, y, z \n",
    "is the location of the global minimum.  The second three are XY with the minimum taken across Z, \n",
    "XZ with the minumum taken across Y, YZ, with the minimum taken across X.\n",
    "With these 6 I think you would get a pretty good idea of the contours around the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('pre_ga_reports.p','rb') as f:\n",
    "    package = pickle.load(f)\n",
    "log = package[3]    \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "fig, axes = plt.subplots(figsize=(10, 10), facecolor='white')\n",
    "gen_numbers = [ i for i in range(0,len(log.select('gen'))) ]\n",
    "\n",
    "mean = np.array([ np.sum(i) for i in log.select('avg')])\n",
    "std = np.array([ np.sum(i) for i in log.select('std')])\n",
    "minimum = np.array([ np.sum(i) for i in log.select('min')])\n",
    "#minimum = np.array([ np.sum(i) for i in log.select('min')])\n",
    "worst = np.max([ sum(g.dtc.scores.values()) for g in grid_results ])\n",
    "#grid_min = np.min([ sum(g.dtc.scores.values()) for g in grid_results ])\n",
    "gwl = [ worst for i in range(0,len(log.select('gen'))) ]\n",
    "grid_min = np.min([ sum(g.dtc.scores.values()) for g in grid_results ])\n",
    "gml = [ grid_min for i in range(0,len(log.select('gen'))) ]\n",
    "\n",
    "stdminus = mean - std\n",
    "stdplus = mean + std\n",
    "\n",
    "axes.plot(\n",
    "    gen_numbers,\n",
    "    mean,\n",
    "    color='black',\n",
    "    linewidth=2,\n",
    "    label='population average')\n",
    "\n",
    "axes.plot(gen_numbers,\n",
    "          gml,\n",
    "          color='blue',\n",
    "        linewidth=2,\n",
    "        label='exhaustive search best')\n",
    "\n",
    "   \n",
    "axes.plot(gen_numbers,\n",
    "          gwl,\n",
    "          color='yellow',\n",
    "        linewidth=2,\n",
    "        label='exhaustive search worst')\n",
    "       \n",
    "\n",
    "\n",
    "axes.plot(\n",
    "    gen_numbers,\n",
    "    minimum,\n",
    "    color='black',\n",
    "    linewidth=2,\n",
    "    label='population minimum')\n",
    "axes.fill_between(gen_numbers, stdminus, stdplus)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('generation')\n",
    "plt.ylabel('error')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_report = make_report(grid_results,pop, 3)\n",
    "\n",
    "from neuronunit.optimization import exhaustive_search as es\n",
    "#dir(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#fig.savefig('pcolormesh_prettyplotlib_labels_other_cmap_diverging.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from neuronunit.optimization.optimization_management import run_ga\n",
    "from neuronunit.optimization.exhaustive_search import run_grid, reduce_params, create_grid\n",
    "from neuronunit.optimization.model_parameters import model_params\n",
    "import os\n",
    "import pickle\n",
    "from neuronunit.optimization import get_neab\n",
    "reports = {}\n",
    "npoints = 10\n",
    "\n",
    "\n",
    "\n",
    "with open('pre_grid_reports.p','rb') as f:\n",
    "    grid_results = pickle.load(f)\n",
    "opt_keys = list(grid_results[0].dtc.attrs.keys())\n",
    "\n",
    "with open('pre_ga_reports.p','rb') as f:\n",
    "    ga_out = pickle.load(f)\n",
    "\n",
    "pop = ga_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from neuronunit.optimization.exhaustive_search import create_grid\n",
    "gp = create_grid(npoints = 6,nparams = 3)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Found tough parameters for which the GA is not able to perform particularily # well. Suspect b's error surface is not concave.\n",
    "Explore 1D cross section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.scatter([g.dtc.attrs['a'] for g in pop ],[ sum(g.dtc.scores.values()) for g in pop ] ,label='ga pop')\n",
    "plt.scatter([g.dtc.attrs['a'] for g in grid_results ],[ sum(g.dtc.scores.values()) for g in grid_results ] ,label='grid evaluations')\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('gene attribute a')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter([g.dtc.attrs['vr'] for g in pop ],[ sum(g.dtc.scores.values()) for g in pop ] ,label='ga pop')\n",
    "plt.scatter([g.dtc.attrs['vr'] for g in grid_results ],[ sum(g.dtc.scores.values()) for g in grid_results ] ,label='grid evaluations')\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('gene attribute vr')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter([g.dtc.attrs['b'] for g in pop ],[ sum(g.dtc.scores.values()) for g in pop ] ,label='ga pop')\n",
    "plt.scatter([g.dtc.attrs['b'] for g in grid_results ],[ sum(g.dtc.scores.values()) for g in grid_results ] ,label='grid evaluations')\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('gene attribute b')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nparams = 3\n",
    "opt_keys = [str('a'),str('vr'),str('b')]\n",
    "\n",
    "\n",
    "#grid_results = run_grid(nparams,npoints,tests,provided_keys = opt_keys)\n",
    "from neuronunit.optimization import exhaustive_search #import run_grid, reduce_params, create_grid\n",
    "\n",
    "from neuronunit.optimization.exhaustive_search import run_grid, reduce_params, create_grid\n",
    "grid_points,maps = exhaustive_search.create_grid(npoints=6,nparams=3,provided_keys=opt_keys)\n",
    "print(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = np.zeros((6,6,6))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in grid_results:\n",
    "    xyz = []\n",
    "    for k,v in i.dtc.attrs.items():\n",
    "        xyz.append(maps[k][v])\n",
    "    grid[xyz[0],xyz[1],xyz[2]] = sum(i.dtc.scores.values())\n",
    "\n",
    "for i in range(0,6):\n",
    "    flat = grid[i,:,:]\n",
    "    plt.imshow(flat)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(0,6):\n",
    "    flat = grid[:,i,:]\n",
    "    plt.imshow(flat)\n",
    "    plt.show()\n",
    "    \n",
    "for i in range(0,6):\n",
    "    flat = grid[:,:,i]\n",
    "    plt.imshow(flat)\n",
    "    plt.show()\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "t = np.arange(0.0, 1.0, 0.001)\n",
    "a0 = 5\n",
    "f0 = 3\n",
    "delta_f = 5.0\n",
    "s = a0*np.sin(2*np.pi*f0*t)\n",
    "l, = plt.plot(t, s, lw=2, color='red')\n",
    "plt.axis([0, 1, -10, 10])\n",
    "\n",
    "axcolor = 'lightgoldenrodyellow'\n",
    "axfreq = plt.axes([0.25, 0.1, 0.65, 0.03], facecolor=axcolor)\n",
    "axamp = plt.axes([0.25, 0.15, 0.65, 0.03], facecolor=axcolor)\n",
    "\n",
    "sfreq = Slider(axfreq, 'Freq', 0.1, 30.0, valinit=f0, valstep=delta_f)\n",
    "samp = Slider(axamp, 'Amp', 0.1, 10.0, valinit=a0)\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    amp = samp.val\n",
    "    freq = sfreq.val\n",
    "    l.set_ydata(amp*np.sin(2*np.pi*freq*t))\n",
    "    fig.canvas.draw_idle()\n",
    "sfreq.on_changed(update)\n",
    "samp.on_changed(update)\n",
    "\n",
    "resetax = plt.axes([0.8, 0.025, 0.1, 0.04])\n",
    "button = Button(resetax, 'Reset', color=axcolor, hovercolor='0.975')\n",
    "\n",
    "\n",
    "def reset(event):\n",
    "    sfreq.reset()\n",
    "    samp.reset()\n",
    "button.on_clicked(reset)\n",
    "\n",
    "rax = plt.axes([0.025, 0.5, 0.15, 0.15], facecolor=axcolor)\n",
    "radio = RadioButtons(rax, ('red', 'blue', 'green'), active=0)\n",
    "\n",
    "\n",
    "def colorfunc(label):\n",
    "    l.set_color(label)\n",
    "    fig.canvas.draw_idle()\n",
    "radio.on_clicked(colorfunc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_list = genes_vs_gen[1:-0]\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#![alt text](rick_style_guide.png \"Ricks table guide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attrs_ = [ list(p.dtc.attrs.keys()) for i,p in history.genealogy_history.items() ]\n",
    "attrs = attrs_[0]\n",
    "print(attrs)\n",
    "\n",
    "scores_ = [ list(p.dtc.scores.keys()) for i,p in history.genealogy_history.items() ]\n",
    "scores = scores_[0]\n",
    "from collections import OrderedDict\n",
    "\n",
    "urlDats = []\n",
    "hi = [ (i,p) for i,p in history.genealogy_history.items() ]\n",
    "sc = [ (i,p) for i,p in enumerate(grid_results) ]\n",
    "\n",
    "def history_iter(mapped):\n",
    "    i,p = mapped\n",
    "    urlDat = OrderedDict()\n",
    "    urlDat['gene_number'] = i\n",
    "    \n",
    "    attrs = list(p.dtc.attrs.keys()) \n",
    "    scores = list(p.dtc.scores.keys()) \n",
    "    for a in attrs:\n",
    "        urlDat[a] = p.dtc.attrs[a]    \n",
    "    scores0 = scores[0]\n",
    "    for s in scores:\n",
    "        urlDat[s] = p.dtc.scores[s]\n",
    "    urlDat[str('total')] = sum(p.dtc.scores.values())\n",
    "    for k,v in p.dtc.score.items():\n",
    "        urlDat[str(k)+str('_observation')] = v['observation']['mean'] \n",
    "        urlDat[str(k)+str('_prediction')] = v['observation']['mean'] \n",
    "    for k,v in p.dtc.scores.items():\n",
    "        urlDat[str(k)] = v\n",
    "\n",
    "\n",
    "    return urlDat\n",
    "    \n",
    "def process_dics(urlDats):\n",
    "    dfs = []\n",
    "    for urlDat in urlDats:\n",
    "        # pandas Data frames are best data container for maths/stats, but steep learning curve.\n",
    "        # Other exclusion criteria. Exclude reading levels above grade 100,\n",
    "        # as this is most likely a problem with the metric algorithm, and or rubbish data in.\n",
    "        # TODO: speed everything up, by performing exclusion criteri above not here.\n",
    "        if len(dfs) == 0:\n",
    "            dfs = pd.DataFrame(pd.Series(urlDat)).T\n",
    "        dfs = pd.concat([ dfs, pd.DataFrame(pd.Series(urlDat)).T ])\n",
    "    return dfs\n",
    "\n",
    "genes = list(map(history_iter,hi))    \n",
    "print(urlDats)\n",
    "dfg = process_dics(genes)\n",
    "\n",
    "grids = list(map(history_iter,sc))    \n",
    "dfs = process_dics(grids)\n",
    "\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am currently writing code that should enable the plotting of HOF values versus generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason the global minimum solution is not converged on, as shown by the evolution of errors below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, the GA population does not converge to the absolute minimum, although it does sample it.\n",
    "Perhaps the absolute minimum is a highly dominated solution, which is a testable hypthosis.\n",
    "\n",
    "None the less because the GA samples the absolute minimum, this value can be corroborated with the GA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize distance between minimimum error and maximum error.\n",
    "This step will allow the GA's performance to be located within or below the range of error found by grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below reports on the differences between between attributes of best models found via grid versus attributes of best models found via GA search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
